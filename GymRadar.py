# Import c√°c th∆∞ vi·ªán c·ªët l√µi
import json
import os
import math
import re
from datetime import datetime
from difflib import SequenceMatcher
from typing import List, Optional

# Import c√°c th∆∞ vi·ªán b√™n ngo√†i
import google.generativeai as genai
import pyodbc
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# C·∫•u h√¨nh Gemini API
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# C·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu
db_user = os.getenv('DB_USER')
db_password = os.getenv('DB_PASSWORD')

# X√¢y d·ª±ng chu·ªói k·∫øt n·ªëi
if not db_user and not db_password:
    conn_str = (
        r"DRIVER={ODBC Driver 17 for SQL Server};"
        f"SERVER={os.getenv('DB_SERVER')};"
        f"DATABASE={os.getenv('DB_NAME')};"
        "Trusted_Connection=yes;"
    )
else:
    conn_str = (
        r"DRIVER={ODBC Driver 17 for SQL Server};"
        f"SERVER={os.getenv('DB_SERVER')};"
        f"DATABASE={os.getenv('DB_NAME')};"
        f"UID={db_user};"
        f"PWD={db_password};"
    )

# K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu
try:
    print("ƒêang k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu...")
    print(f"Server: {os.getenv('DB_SERVER')}")
    print(f"Database: {os.getenv('DB_NAME')}")
    
    conn = pyodbc.connect(conn_str)
    cursor = conn.cursor()
    print("K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu th√†nh c√¥ng!")
    
except pyodbc.Error as e:
    print(f"K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu th·∫•t b·∫°i: {e}")
    print("Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu")
    conn = None
    cursor = None

# Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
model = genai.GenerativeModel("gemini-2.0-flash")

class ChatRequest(BaseModel):
    prompt: str
    longitude: Optional[float] = None
    latitude: Optional[float] = None
    conversation_history: Optional[List[dict]] = []

class ChatResponse(BaseModel):
    promptResponse: str
    gyms: Optional[List[dict]] = None
    conversation_history: Optional[List[dict]] = []

def build_conversation_context(conversation_history: List[dict]) -> str:
    """X√¢y d·ª±ng ng·ªØ c·∫£nh t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    if not conversation_history:
        return ""
    
    context_parts = []
    for msg in conversation_history[-10:]:  # L·∫•y 10 tin nh·∫Øn g·∫ßn nh·∫•t l√†m ng·ªØ c·∫£nh
        role_label = "Ng∆∞·ªùi d√πng" if msg.get("role") == "user" else "GymRadar"
        content = sanitize_text_for_json(msg.get('content', ''))
        context_parts.append(f"{role_label}: {content}")
    
    return "\n".join(context_parts)

def sanitize_text_for_json(text: str) -> str:
    """L√†m s·∫°ch text ƒë·ªÉ tr√°nh l·ªói JSON parsing"""
    if not text:
        return ""
    
    # Thay th·∫ø c√°c k√Ω t·ª± ƒëi·ªÅu khi·ªÉn c√≥ th·ªÉ g√¢y l·ªói JSON
    try:
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒëi·ªÅu khi·ªÉn kh√¥ng mong mu·ªën
        cleaned_text = text.replace('\x00', '').replace('\x08', '').replace('\x0c', '')
        cleaned_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', cleaned_text)
        
        # ƒê·∫£m b·∫£o text c√≥ th·ªÉ ƒë∆∞·ª£c encode th√†nh JSON
        json.dumps(cleaned_text)
        return cleaned_text
    except (UnicodeDecodeError, json.JSONDecodeError):
        # N·∫øu v·∫´n c√≥ l·ªói, encode/decode ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá
        return text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

def safe_get_row_data(row):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√†ng c∆° s·ªü d·ªØ li·ªáu m·ªôt c√°ch an to√†n"""
    try:
        def get_attr(attr_name, default=None):
            try:
                return getattr(row, attr_name, default)
            except AttributeError:
                return default
        
        def get_bool_attr(attr_name, default=False):
            try:
                value = getattr(row, attr_name, default)
                if value is None:
                    return default
                if isinstance(value, int):
                    return bool(value)
                if isinstance(value, str):
                    return value.lower() in ('true', '1', 'yes', 'on')
                return bool(value)
            except AttributeError:
                return default
        
        def format_date(date_field):
            if date_field:
                try:
                    return date_field.isoformat() if hasattr(date_field, 'isoformat') else str(date_field)
                except:
                    return None
            return None
        
        gym_data = {
            "id": str(get_attr('Id', '')),
            "gymName": get_attr('GymName', ''),
            "since": format_date(get_attr('Since')),
            "address": get_attr('Address', ''),
            "representName": get_attr('RepresentName', ''),
            "taxCode": get_attr('TaxCode', ''),
            "longitude": get_attr('Longitude'),
            "latitude": get_attr('Latitude'),
            "qrCode": get_attr('QRCode', ''),
            "hotResearch": get_bool_attr('HotResearch', False),
            "accountId": str(get_attr('AccountId', '')) if get_attr('AccountId') else None,
            "active": get_bool_attr('Active', True),
            "createAt": format_date(get_attr('CreateAt')),
            "updateAt": format_date(get_attr('UpdateAt')),
            "deleteAt": format_date(get_attr('DeleteAt')),
            "mainImage": get_attr('MainImage', '')
        }
        
        # Handle distance for nearby queries
        distance = get_attr('distance_km')
        if distance is not None:
            try:
                gym_data["distance_km"] = round(float(distance), 2)
            except:
                gym_data["distance_km"] = 0
        
        return gym_data
        
    except Exception as e:
        print(f"L·ªói trong safe_get_row_data: {str(e)}")
        return {
            "id": "",
            "gymName": "Ph√≤ng gym kh√¥ng x√°c ƒë·ªãnh",
            "since": None,
            "address": "",
            "representName": "",
            "taxCode": "",
            "longitude": None,
            "latitude": None,
            "qrCode": "",
            "hotResearch": False,
            "accountId": None,
            "active": True,
            "createAt": None,
            "updateAt": None,
            "deleteAt": None,
            "mainImage": ""
        }

# Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI
app = FastAPI(
    title="GymRadar Chatbot AI",
    description="Chatbot t√¨m ki·∫øm ph√≤ng gym th√¥ng minh s·ª≠ d·ª•ng Gemini AI v√† SQL Server",
    version="2.0.0"
)

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# H√†m truy v·∫•n c∆° s·ªü d·ªØ li·ªáu
def query_database(query):
    if conn is None or cursor is None:
        print("K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu kh√¥ng kh·∫£ d·ª•ng")
        return "L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu"
    
    try:
        print(f"ƒêang th·ª±c thi truy v·∫•n: {query}")
        cursor.execute(query)
        results = cursor.fetchall()
        print(f"K·∫øt qu·∫£ truy v·∫•n: {len(results)} h√†ng")
        return results
    except pyodbc.Error as e:
        print(f"L·ªói c∆° s·ªü d·ªØ li·ªáu: {str(e)}")
        return f"L·ªói c∆° s·ªü d·ªØ li·ªáu: {str(e)}"

# X√¢y d·ª±ng truy v·∫•n SQL ƒë·ªÉ t√¨m gym g·∫ßn
def build_nearby_gym_query(longitude, latitude, max_distance_km= 10):
    """X√¢y d·ª±ng truy v·∫•n SQL ƒë·ªÉ t√¨m gym g·∫ßn s·ª≠ d·ª•ng c√¥ng th·ª©c Haversine"""
    # T·ªëi ∆∞u h√≥a v·ªõi bounding box ƒë·ªÉ gi·∫£m t·∫£i t√≠nh to√°n
    lat_range = max_distance_km / 111.0  # 1 ƒë·ªô vƒ© ƒë·ªô ‚âà 111km
    lng_range = max_distance_km / (111.0 * abs(math.cos(math.radians(latitude))))
    
    return f"""
    WITH BoundedGyms AS (
        SELECT 
            Id, GymName, Since, Address, RepresentName, TaxCode,
            CAST(Longitude AS FLOAT) AS Longitude,
            CAST(Latitude AS FLOAT) AS Latitude,
            QRCode, HotResearch, AccountId, Active,
            CreateAt, UpdateAt, DeleteAt, MainImage
        FROM dbo.Gym 
        WHERE Active = 1
        AND CAST(Latitude AS FLOAT) BETWEEN {latitude - lat_range} AND {latitude + lat_range}
        AND CAST(Longitude AS FLOAT) BETWEEN {longitude - lng_range} AND {longitude + lng_range}
    ),
    DistanceCalculated AS (
        SELECT *,
            6371.0 * 2 * ASIN(
                SQRT(
                    POWER(SIN(RADIANS({latitude} - Latitude) / 2), 2) +
                    COS(RADIANS({latitude})) * COS(RADIANS(Latitude)) *
                    POWER(SIN(RADIANS({longitude} - Longitude) / 2), 2)
                )
            ) AS distance_km
        FROM BoundedGyms
    )
    SELECT * 
    FROM DistanceCalculated
    WHERE distance_km <= {max_distance_km}
    ORDER BY distance_km ASC, HotResearch DESC, GymName ASC;
    """

def get_nearby_distance_preference(user_input):
    """Ph√¢n t√≠ch ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ x√°c ƒë·ªãnh b√°n k√≠nh t√¨m ki·∫øm ph√π h·ª£p"""
    user_input_lower = user_input.lower()
    
    # 1. T√¨m s·ªë km c·ª• th·ªÉ trong c√¢u (∆∞u ti√™n cao nh·∫•t)
    import re
    km_match = re.search(r'(\d+)\s*km', user_input_lower)
    if km_match:
        distance = int(km_match.group(1))
        # Gi·ªõi h·∫°n kho·∫£ng c√°ch h·ª£p l√Ω (1-50km)
        return max(1, min(distance, 50))
    
    # 2. Ph√¢n t√≠ch theo c·∫•p ƒë·ªô kho·∫£ng c√°ch v·ªõi t·ª´ kh√≥a th√¥ng minh
    distance_patterns = {
        # R·∫•t g·∫ßn - 2km
        2: [
            r'(r·∫•t g·∫ßn|very close|walking distance|ƒëi b·ªô|ƒëi b·ªô ƒë∆∞·ª£c)',
            r'(ngay g·∫ßn|s√°t b√™n|c·ª±c g·∫ßn|si√™u g·∫ßn)',
            r'(trong ph·∫°m vi \d{1,3}\s*m|d∆∞·ªõi 1km|under 1km)'
        ],
        
        # G·∫ßn - 5km  
        5: [
            r'(g·∫ßn|nearby|close|l√¢n c·∫≠n|k·ªÅ b√™n)',
            r'(quanh ƒë√¢y|xung quanh|around here)',
            r'(kh√¥ng xa|not far|g·∫ßn nh√†|near home)'
        ],
        
        # Trung b√¨nh - 10km
        10: [
            r'(khu v·ª±c|trong khu|in the area|local)',
            r'(xa m·ªôt ch√∫t|bit farther|h∆°i xa)',
            r'(trong th√†nh ph·ªë|in the city|c√πng th√†nh ph·ªë)'
        ],
        
        # Xa - 15km
        15: [
            r'(xa h∆°n|farther|more distant)',
            r'(trong t·ªânh|in province|c√πng t·ªânh)',
            r'(m·ªü r·ªông|expand|extend)'
        ],
        
        # R·∫•t xa - 25km
        25: [
            r'(r·∫•t xa|very far|distant)',
            r'(kh·∫Øp n∆°i|everywhere|anywhere)',
            r'(to√†n b·ªô|all|entire|whole)'
        ],
        
        # Kh√¥ng gi·ªõi h·∫°n - 50km
        50: [
            r'(t·∫•t c·∫£|all gyms|m·ªçi|every|b·∫•t k·ª≥ ƒë√¢u)',
            r'(kh√¥ng gi·ªõi h·∫°n|unlimited|no limit)',
            r'(to√†n qu·ªëc|nationwide|whole country)'
        ]
    }
    
    # 3. Duy·ªát qua c√°c pattern theo th·ª© t·ª± ∆∞u ti√™n
    for distance, patterns in distance_patterns.items():
        for pattern in patterns:
            if re.search(pattern, user_input_lower):
                return distance
    
    # 4. Ph√¢n t√≠ch th√¥ng minh d·ª±a tr√™n ng·ªØ c·∫£nh
    
    # N·∫øu c√≥ t·ª´ kh√≥a v·ªÅ ph∆∞∆°ng ti·ªán di chuy·ªÉn
    transport_keywords = {
        r'(xe ƒë·∫°p|bicycle|bike)': 8,
        r'(xe m√°y|motorbike|scooter)': 15, 
        r'(√¥ t√¥|car|drive|driving)': 20,
        r'(xe bus|bus|public transport)': 12
    }
    
    for pattern, distance in transport_keywords.items():
        if re.search(pattern, user_input_lower):
            return distance
    
    # N·∫øu c√≥ t·ª´ kh√≥a v·ªÅ th·ªùi gian
    time_keywords = {
        r'(5 ph√∫t|5min|nƒÉm ph√∫t)': 3,
        r'(10 ph√∫t|10min|m∆∞·ªùi ph√∫t)': 5,
        r'(15 ph√∫t|15min|m∆∞·ªùi lƒÉm ph√∫t)': 8,
        r'(20 ph√∫t|20min|hai m∆∞∆°i ph√∫t)': 12,
        r'(30 ph√∫t|30min|n·ª≠a gi·ªù|half hour)': 18
    }
    
    for pattern, distance in time_keywords.items():
        if re.search(pattern, user_input_lower):
            return distance
    
    # 5. Ph√¢n t√≠ch theo ƒë·ªãa danh c·ª• th·ªÉ
    location_keywords = {
        r'(qu·∫≠n \d+|district \d+)': 8,        # Trong qu·∫≠n
        r'(th√†nh ph·ªë|city|tp\.)': 15,         # Trong th√†nh ph·ªë  
        r'(t·ªânh|province|t·ªânh th√†nh)': 25,    # Trong t·ªânh
        r'(huy·ªán|county|suburban)': 20        # Ngo·∫°i th√†nh
    }
    
    for pattern, distance in location_keywords.items():
        if re.search(pattern, user_input_lower):
            return distance
    
    # 6. M·∫∑c ƒë·ªãnh th√¥ng minh d·ª±a tr√™n ƒë·ªô d√†i c√¢u
    if len(user_input_lower.split()) <= 3:
        return 8   # C√¢u ng·∫Øn -> t√¨m g·∫ßn
    elif len(user_input_lower.split()) <= 6:
        return 10  # C√¢u trung b√¨nh -> t√¨m v·ª´a
    else:
        return 12  # C√¢u d√†i -> c√≥ th·ªÉ mu·ªën t√¨m r·ªông h∆°n

def format_distance_friendly(distance_km):
    """ƒê·ªãnh d·∫°ng kho·∫£ng c√°ch theo c√°ch th√¢n thi·ªán v·ªõi ng∆∞·ªùi d√πng"""
    if distance_km < 0.5:
        return f"{int(distance_km * 1000)}m"
    elif distance_km < 1:
        return f"{distance_km:.1f}km (ƒëi b·ªô ƒë∆∞·ª£c)" 
    elif distance_km < 3:
        return f"{distance_km:.1f}km (g·∫ßn)"
    elif distance_km < 5:
        return f"{distance_km:.1f}km (xe ƒë·∫°p/xe m√°y)"
    elif distance_km < 10:
        return f"{distance_km:.1f}km (√¥ t√¥/xe m√°y)"
    else:
        return f"{distance_km:.1f}km (xa)"

def normalize_vietnamese_text(text):
    """Chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n"""
    if not text:
        return ""
    
    text = text.lower()
    
    # B·∫£n ƒë·ªì chuy·ªÉn ƒë·ªïi k√Ω t·ª± ti·∫øng Vi·ªát sang Latin
    char_map = {
        '√†': 'a', '√°': 'a', '·∫°': 'a', '·∫£': 'a', '√£': 'a',
        '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫≠': 'a', '·∫©': 'a', '·∫´': 'a',
        'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫∑': 'a', '·∫≥': 'a', '·∫µ': 'a',
        '√®': 'e', '√©': 'e', '·∫π': 'e', '·∫ª': 'e', '·∫Ω': 'e',
        '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªá': 'e', '·ªÉ': 'e', '·ªÖ': 'e',
        '√¨': 'i', '√≠': 'i', '·ªã': 'i', '·ªâ': 'i', 'ƒ©': 'i',
        '√≤': 'o', '√≥': 'o', '·ªç': 'o', '·ªè': 'o', '√µ': 'o',
        '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªô': 'o', '·ªï': 'o', '·ªó': 'o',
        '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ª£': 'o', '·ªü': 'o', '·ª°': 'o',
        '√π': 'u', '√∫': 'u', '·ª•': 'u', '·ªß': 'u', '≈©': 'u',
        '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª±': 'u', '·ª≠': 'u', '·ªØ': 'u',
        '·ª≥': 'y', '√Ω': 'y', '·ªµ': 'y', '·ª∑': 'y', '·ªπ': 'y',
        'ƒë': 'd'
    }
    
    # Thay th·∫ø k√Ω t·ª± ti·∫øng Vi·ªát
    for viet_char, latin_char in char_map.items():
        text = text.replace(viet_char, latin_char)
    
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ ch·ªØ c√°i v√† s·ªë
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    text = ' '.join(text.split())
    
    return text

def fuzzy_search_similarity(text1, text2):
    """T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai chu·ªói vƒÉn b·∫£n"""
    if not text1 or not text2:
        return 0
    
    normalized1 = normalize_vietnamese_text(text1)
    normalized2 = normalize_vietnamese_text(text2)
    
    return SequenceMatcher(None, normalized1, normalized2).ratio()

def extract_search_keywords(user_input):
    """Tr√≠ch xu·∫•t t·ª´ kh√≥a t√¨m ki·∫øm t·ª´ ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng"""
    stop_words = {
        't√¨m', 't√¨m ki·∫øm', 'find', 'search', 'c√≥', 'kh√¥ng', 'gym', 'ph√≤ng gym', 
        'n√†o', 'ƒë√¢u', 'where', 'what', 'g√¨', 'l√†', '·ªü', 't·∫°i', 'trong', 'c·ªßa',
        'm·ªôt', 'v√†i', 'nh·ªØng', 'c√°c', 'the', 'a', 'an', 'and', 'or', 'for'
    }
    
    normalized = normalize_vietnamese_text(user_input)
    words = normalized.split()
    keywords = [word for word in words if word not in stop_words and len(word) >= 2]
    
    return keywords

def intelligent_gym_search(user_input):
    """T√¨m ki·∫øm gym th√¥ng minh v·ªõi kh·∫£ nƒÉng ph√¢n t√≠ch ng·ªØ nghƒ©a n√¢ng cao"""
    try:
        # Ki·ªÉm tra ƒë·∫ßu v√†o
        if not user_input or not isinstance(user_input, str):
            return None
        
        user_input_lower = user_input.lower()
        
        # 1. Danh s√°ch t·ª´ kh√≥a ch·ªâ r√µ KH√îNG c·∫ßn t√¨m ki·∫øm gym (m·ªü r·ªông)
        non_gym_indicators = [
            # Ch√†o h·ªèi v√† l·ªãch s·ª±
            'xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n', 'hey there',
            'c·∫£m ∆°n', 'thank you', 'thanks', 'c√°m ∆°n', 'tks',
            't·∫°m bi·ªát', 'bye', 'goodbye', 'see you',
            
            # C√¢u h·ªèi c√° nh√¢n  
            't√™n t√¥i', 'my name', 'l·∫∑p l·∫°i t√™n', 'nh·∫Øc l·∫°i t√™n',
            't√¥i l√† ai', 'who am i', 'remember me',
            
            # T∆∞ v·∫•n s·ª©c kh·ªèe kh√¥ng c·∫ßn gym c·ª• th·ªÉ
            'l√†m sao ƒë·ªÉ', 'how to', 'c√°ch ƒë·ªÉ', 'how can i',
            'ƒÉn g√¨ ƒë·ªÉ', 'what to eat', 'what should i eat',
            'b√†i t·∫≠p n√†o', 'what exercise', 'which workout',
            'tƒÉng c√¢n', 'gi·∫£m c√¢n', 'lose weight', 'gain weight',
            'th·ªùi ti·∫øt', 'weather', 'nhi·ªát ƒë·ªô', 'temperature',
            
            # Ph·∫£n h·ªìi chung
            'ok', 'ƒë∆∞·ª£c r·ªìi', 't·ªët', 'good', 'fine', 'great',
            'ƒë·ªìng √Ω', 'agree', 'yes', 'no problem'
        ]
        
        # N·∫øu c√≥ t·ª´ kh√≥a kh√¥ng li√™n quan gym, return None ngay
        if any(indicator in user_input_lower for indicator in non_gym_indicators):
            return None
        
        # 2. Ph√¢n t√≠ch √Ω ƒë·ªãnh t√¨m ki·∫øm gym (c·∫£i thi·ªán)
        gym_search_patterns = [
            # T√¨m ki·∫øm tr·ª±c ti·∫øp
            r'(t√¨m|find|search|looking for)\s*(gym|ph√≤ng gym|fitness|th·ªÉ d·ª•c)',
            r'(gym|ph√≤ng gym|fitness)\s*(n√†o|what|which|where)',
            r'(c√≥|is there|are there)\s*(gym|ph√≤ng gym|fitness)',
            
            # T√¨m ki·∫øm theo ƒë·ªãa ƒëi·ªÉm
            r'(gym|ph√≤ng gym|fitness)\s*(·ªü|at|in|near|g·∫ßn)\s*(\w+)',
            r'(qu·∫≠n|district|huy·ªán|th√†nh ph·ªë|city)\s*\d*.*?(gym|ph√≤ng gym|fitness)',
            
            # T√¨m ki·∫øm theo ƒë·∫∑c ƒëi·ªÉm
            r'(gym|ph√≤ng gym|fitness)\s*(hot|n·ªïi ti·∫øng|ph·ªï bi·∫øn|t·ªët|best)',
            r'(hot|n·ªïi ti·∫øng|ph·ªï bi·∫øn|t·ªët|best)\s*(gym|ph√≤ng gym|fitness)',
            
            # T√¨m ki·∫øm m·ªü
            r'(danh s√°ch|list)\s*(gym|ph√≤ng gym|fitness)',
            r'(t·∫•t c·∫£|all)\s*(gym|ph√≤ng gym|fitness)',
            r'(nh·ªØng|the)\s*(gym|ph√≤ng gym|fitness)\s*(n√†o|what)'
        ]
        
        # Ki·ªÉm tra xem c√≥ kh·ªõp v·ªõi pattern t√¨m ki·∫øm gym kh√¥ng
        has_gym_search_intent = any(re.search(pattern, user_input_lower) for pattern in gym_search_patterns)
        
        # N·∫øu kh√¥ng c√≥ √Ω ƒë·ªãnh t√¨m ki·∫øm gym r√µ r√†ng, return None
        if not has_gym_search_intent:
            return None
        
        # 3. Tr√≠ch xu·∫•t th√¥ng tin t√¨m ki·∫øm th√¥ng minh
        search_info = {
            'keywords': [],
            'location': None,
            'hot_search': False,
            'search_type': 'general'
        }
        
        # Tr√≠ch xu·∫•t t·ª´ kh√≥a quan tr·ªçng (b·ªè stop words)
        stop_words = {
            't√¨m', 'find', 'search', 'c√≥', 'kh√¥ng', 'n√†o', 'ƒë√¢u', 'where', 
            'what', 'g√¨', 'l√†', '·ªü', 't·∫°i', 'trong', 'c·ªßa', 'm·ªôt', 'v√†i', 
            'nh·ªØng', 'c√°c', 'the', 'a', 'an', 'and', 'or', 'for', 'gym', 
            'ph√≤ng', 'fitness', 'center', 'club'
        }
        
        words = re.findall(r'\b\w+\b', normalize_vietnamese_text(user_input))
        keywords = [word for word in words if word not in stop_words and len(word) >= 2]
        search_info['keywords'] = keywords[:5]  # L·∫•y t·ªëi ƒëa 5 t·ª´ kh√≥a quan tr·ªçng nh·∫•t
        
        # Ph√°t hi·ªán t√¨m ki·∫øm hot/ph·ªï bi·∫øn
        hot_patterns = [
            r'(hot|n·ªïi ti·∫øng|ph·ªï bi·∫øn|ƒë∆∞·ª£c y√™u th√≠ch|t·ªët nh·∫•t|best|top)',
            r'(recommend|g·ª£i √Ω|ƒë·ªÅ xu·∫•t|suggest)'
        ]
        search_info['hot_search'] = any(re.search(pattern, user_input_lower) for pattern in hot_patterns)
        
        # Ph√°t hi·ªán ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ
        location_patterns = [
            r'(qu·∫≠n|district)\s*(\d+)',
            r'(huy·ªán|county)\s*(\w+)',
            r'(th√†nh ph·ªë|city|tp\.?)\s*(\w+)',
            r'(·ªü|t·∫°i|in|at)\s*(\w+)'
        ]
        
        for pattern in location_patterns:
            match = re.search(pattern, user_input_lower)
            if match:
                search_info['location'] = match.group(0)
                break
        
        # 4. X√¢y d·ª±ng truy v·∫•n SQL th√¥ng minh
        base_conditions = ["Active = 1"]
        
        # ∆Øu ti√™n gym hot n·∫øu c√≥ y√™u c·∫ßu
        if search_info['hot_search']:
            base_conditions.append("HotResearch = 1")
            search_info['search_type'] = 'hot'
        
        # X√¢y d·ª±ng ƒëi·ªÅu ki·ªán t√¨m ki·∫øm t·ª´ keywords
        search_conditions = []
        valid_keywords = []
        
        for keyword in search_info['keywords']:
            if keyword and len(keyword) >= 2:
                # Escape single quotes ƒë·ªÉ tr√°nh SQL injection
                safe_keyword = keyword.replace("'", "''")
                valid_keywords.append(safe_keyword)
                search_conditions.extend([
                    f"GymName LIKE '%{safe_keyword}%'",
                    f"Address LIKE '%{safe_keyword}%'",
                    f"RepresentName LIKE '%{safe_keyword}%'"
                ])
        
        # Th√™m ƒëi·ªÅu ki·ªán ƒë·ªãa ƒëi·ªÉm n·∫øu c√≥
        if search_info['location']:
            safe_location = search_info['location'].replace("'", "''")
            search_conditions.extend([
                f"Address LIKE '%{safe_location}%'",
                f"GymName LIKE '%{safe_location}%'"
            ])
        
        # X√¢y d·ª±ng m·ªánh ƒë·ªÅ WHERE
        where_clause = " AND ".join(base_conditions)
        
        if search_conditions:
            keyword_clause = " OR ".join(search_conditions)
            where_clause += f" OR ({keyword_clause})"
        elif not search_info['hot_search']:
            # N·∫øu kh√¥ng c√≥ t·ª´ kh√≥a v√† kh√¥ng ph·∫£i t√¨m ki·∫øm hot, return None
            return None
        
        # 5. T·∫°o SQL query v·ªõi scoring th√¥ng minh
        if valid_keywords:
            primary_keyword = valid_keywords[0]
            sql_query = f"""
            SELECT *, 
                   CASE WHEN HotResearch = 1 THEN 20 ELSE 0 END as hot_score,
                   CASE 
                       WHEN GymName LIKE '%{primary_keyword}%' THEN 30
                       WHEN Address LIKE '%{primary_keyword}%' THEN 25
                       WHEN RepresentName LIKE '%{primary_keyword}%' THEN 15
                       ELSE 5
                   END as relevance_score,
                   CASE 
                       WHEN CreateAt >= DATEADD(year, -1, GETDATE()) THEN 5 
                       ELSE 0 
                   END as recency_score
            FROM dbo.Gym 
            WHERE {where_clause}
            ORDER BY hot_score DESC, relevance_score DESC, recency_score DESC, GymName ASC
            """
        else:
            # Query cho t√¨m ki·∫øm general ho·∫∑c hot gym
            sql_query = f"""
            SELECT *, 
                   CASE WHEN HotResearch = 1 THEN 20 ELSE 0 END as hot_score,
                   10 as relevance_score,
                   CASE 
                       WHEN CreateAt >= DATEADD(year, -1, GETDATE()) THEN 5 
                       ELSE 0 
                   END as recency_score
            FROM dbo.Gym 
            WHERE {where_clause}
            ORDER BY hot_score DESC, relevance_score DESC, recency_score DESC, GymName ASC
            """
        
        print(f"ü§ñ INTELLIGENT SEARCH: Input='{user_input}' | Type={search_info['search_type']} | Keywords={search_info['keywords'][:3]}")
        return sql_query
        
    except Exception as e:
        print(f"L·ªói trong intelligent_gym_search: {str(e)}")
        return None

def detect_search_intent(user_input):
    """Ph√°t hi·ªán √Ω ƒë·ªãnh t√¨m ki·∫øm t·ª´ ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng"""
    user_lower = user_input.lower()
    
    intent_patterns = {
        'location_search': [r'(g·∫ßn|near|nearby|xung quanh|l√¢n c·∫≠n|quanh ƒë√¢y)', r'(district \d+|qu·∫≠n \d+|huy·ªán)'],
        'name_search': [r'(t√¨m .+ gym|gym .+|.+ fitness|.+ center)'],
        'popular_search': [r'(hot|n·ªïi ti·∫øng|ph·ªï bi·∫øn|ƒë∆∞·ª£c y√™u th√≠ch|t·ªët nh·∫•t|best)', r'(gym hot|ph√≤ng gym hot|fitness hot)'],
        'new_search': [r'(m·ªõi|new|v·ª´a m·ªü|recently|g·∫ßn ƒë√¢y)'],
        'old_search': [r'(c≈©|old|l√¢u nƒÉm|uy t√≠n|established)'],
        'price_search': [r'(r·∫ª|cheap|affordable|gi√° t·ªët|budget)'],
        'equipment_search': [r'(thi·∫øt b·ªã|equipment|m√°y t·∫≠p|facilities)']
    }
    
    detected_intents = []
    for intent, patterns in intent_patterns.items():
        for pattern in patterns:
            if re.search(pattern, user_lower):
                detected_intents.append(intent)
                break
    
    return detected_intents

def classify_query(user_input):
    """Ph√¢n lo·∫°i truy v·∫•n v√† t·∫°o SQL n·∫øu c·∫ßn - ƒê∆∞·ª£c c·∫£i thi·ªán"""
    try:
        # 1. ∆Øu ti√™n s·ª≠ d·ª•ng intelligent search tr∆∞·ªõc
        intelligent_query = intelligent_gym_search(user_input)
        if intelligent_query:
            print(f"‚úÖ INTELLIGENT_SEARCH: Query generated successfully")
            return True, intelligent_query
        
        # 2. N·∫øu intelligent search kh√¥ng t·∫°o ƒë∆∞·ª£c query, c√≥ nghƒ©a l√†:
        # - C√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn t√¨m ki·∫øm gym
        # - Ho·∫∑c l√† c√¢u h·ªèi ch√†o h·ªèi, t∆∞ v·∫•n chung
        
        user_input_lower = user_input.lower()
        
        # 3. Ki·ªÉm tra m·ªôt s·ªë tr∆∞·ªùng h·ª£p ƒë·∫∑c bi·ªát cu·ªëi c√πng
        special_gym_cases = [
            'danh s√°ch gym', 'list gym', 'all gym', 't·∫•t c·∫£ gym',
            'gym c√≥ nh·ªØng g√¨', 'gym n√†o', 'which gym'
        ]
        
        if any(case in user_input_lower for case in special_gym_cases):
            # Tr∆∞·ªùng h·ª£p mu·ªën xem t·∫•t c·∫£ gym
            return True, """
            SELECT *, 
                   CASE WHEN HotResearch = 1 THEN 20 ELSE 0 END as hot_score,
                   10 as relevance_score
            FROM dbo.Gym 
            WHERE Active = 1
            ORDER BY hot_score DESC, GymName ASC
            """
        
        # 4. N·∫øu kh√¥ng kh·ªõp v·ªõi tr∆∞·ªùng h·ª£p n√†o -> kh√¥ng c·∫ßn query database
        print(f"‚ùå NO_DB_QUERY: '{user_input}' kh√¥ng c·∫ßn truy v·∫•n database")
        return False, None
        
    except Exception as e:
        print(f"L·ªói trong classify_query: {str(e)}")
        return False, None

def get_response_with_history(user_input, conversation_history=None, longitude=None, latitude=None):
    """H√†m ch√≠nh ƒë·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    try:
        if conversation_history is None:
            conversation_history = []
        
        conversation_context = build_conversation_context(conversation_history)
        
        # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        current_conversation = conversation_history.copy()
        current_conversation.append({
            "role": "user",
            "content": sanitize_text_for_json(user_input),
            "timestamp": datetime.now().isoformat()
        })
        
        # X·ª≠ l√Ω t√¨m ki·∫øm g·∫ßn v·ªõi t·ªça ƒë·ªô
        if longitude and latitude and any(keyword in user_input.lower() for keyword in ["g·∫ßn", "near", "nearby", "xung quanh", "l√¢n c·∫≠n", "g·∫ßn ƒë√¢y", "quanh ƒë√¢y"]):
            max_distance = get_nearby_distance_preference(user_input)
            print(f"üéØ SMART RADIUS: User input '{user_input}' ‚Üí B√°n k√≠nh ƒë∆∞·ª£c ch·ªçn: {max_distance}km")
            
            sql_query = build_nearby_gym_query(longitude, latitude, max_distance)
            results = query_database(sql_query)

            if isinstance(results, str) or not results:
                response_text = f"ü§î Kh√¥ng t√¨m th·∫•y gym n√†o trong b√°n k√≠nh {max_distance}km. H√£y th·ª≠ m·ªü r·ªông khu v·ª±c t√¨m ki·∫øm!"
                current_conversation.append({
                    "role": "assistant",
                    "content": sanitize_text_for_json(response_text),
                    "timestamp": datetime.now().isoformat()
                })
                return {
                    "promptResponse": sanitize_text_for_json(response_text),
                    "conversation_history": current_conversation
                }

            gyms = [safe_get_row_data(row) for row in results]
            print(f"üîç DEBUG: T√¨m th·∫•y {len(gyms)} gym trong b√°n k√≠nh {max_distance}km")
            for i, gym in enumerate(gyms):
                print(f"  {i+1}. {gym['gymName']} - {gym.get('distance_km', 'N/A')}km")
            
            prompt_response = create_simple_response(gyms, user_input, is_nearby=True)

            current_conversation.append({
                "role": "assistant",
                "content": sanitize_text_for_json(prompt_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "gyms": gyms, 
                "promptResponse": sanitize_text_for_json(prompt_response),
                "conversation_history": current_conversation
            }
        
        # Truy v·∫•n c∆° s·ªü d·ªØ li·ªáu th√¥ng th∆∞·ªùng
        is_db_query, sql_query = classify_query_with_context(user_input, conversation_context)
        print(f"üîç QUERY_CLASSIFICATION: is_db_query={is_db_query}, user_input='{user_input}'")
        
        if is_db_query:
            results = query_database(sql_query)
            if isinstance(results, str) or not results:
                response_text = "ü§î Kh√¥ng t√¨m th·∫•y gym n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ c·ªßa b·∫°n. H√£y th·ª≠ t√¨m ki·∫øm kh√°c!"
                current_conversation.append({
                    "role": "assistant",
                    "content": sanitize_text_for_json(response_text),
                    "timestamp": datetime.now().isoformat()
                })
                return {
                    "promptResponse": sanitize_text_for_json(response_text),
                    "conversation_history": current_conversation
                }

            gyms = [safe_get_row_data(row) for row in results]
            print(f"üéØ SEARCH_RESULT: T√¨m th·∫•y {len(gyms)} gym t·ª´ database")
            
            prompt_response = create_simple_response(gyms, user_input)

            current_conversation.append({
                "role": "assistant",
                "content": sanitize_text_for_json(prompt_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "gyms": gyms, 
                "promptResponse": sanitize_text_for_json(prompt_response),
                "conversation_history": current_conversation
            }

        # H·ªôi tho·∫°i t·ª± do v·ªõi Gemini
        enhanced_context = f"""
        B·∫°n l√† GymRadar AI - tr·ª£ l√Ω t√¨m ki·∫øm ph√≤ng gym th√¢n thi·ªán v√† chuy√™n nghi·ªáp t·∫°i Vi·ªát Nam.
        
        Kh·∫£ nƒÉng:
        - ƒê∆∞a ra g·ª£i √Ω ph√≤ng gym v√† th√¥ng tin chi ti·∫øt
        - T∆∞ v·∫•n th·ªÉ d·ª•c v√† l·ªãch t·∫≠p luy·ªán d·ª±a tr√™n m·ª•c ti√™u
        - Chia s·∫ª ki·∫øn th·ª©c v·ªÅ s·ª©c kh·ªèe v√† th·ªÉ h√¨nh
        - Nh·ªõ ng·ªØ c·∫£nh h·ªôi tho·∫°i ƒë·ªÉ t∆∞ v·∫•n nh·∫•t qu√°n
        
        Phong c√°ch: Th√¢n thi·ªán, chuy√™n nghi·ªáp, hi·ªÉu bi·∫øt. S·ª≠ d·ª•ng emoji ph√π h·ª£p.
        Lu√¥n k·∫øt th√∫c b·∫±ng c√¢u h·ªèi ho·∫∑c g·ª£i √Ω h√†nh ƒë·ªông.
        
        L·ªãch s·ª≠ h·ªôi tho·∫°i:
        {conversation_context}
        """
        
        prompt = f"{enhanced_context}\n\nC√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_input}"
        response = model.generate_content(prompt)
        
        current_conversation.append({
            "role": "assistant", 
            "content": sanitize_text_for_json(response.text),
            "timestamp": datetime.now().isoformat()
        })
        
        return {
            "promptResponse": sanitize_text_for_json(response.text),
            "conversation_history": current_conversation
        }

    except Exception as e:
        print(f"L·ªói trong get_response_with_history: {str(e)}")
        error_response = "ü§ñ Xin l·ªói, ƒë√£ x·∫£y ra l·ªói h·ªá th·ªëng. Vui l√≤ng th·ª≠ l·∫°i!"
        
        if 'current_conversation' in locals():
            current_conversation.append({
                "role": "assistant", 
                "content": sanitize_text_for_json(error_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "promptResponse": sanitize_text_for_json(error_response),
                "conversation_history": current_conversation
            }
        
        return {"promptResponse": sanitize_text_for_json(error_response)}

def create_simple_response(gyms, user_input, is_nearby=False):
    """T·∫°o ph·∫£n h·ªìi ƒë∆°n gi·∫£n cho k·∫øt qu·∫£ t√¨m ki·∫øm gym"""
    if not gyms:
        return "ü§î Kh√¥ng t√¨m th·∫•y gym n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ c·ªßa b·∫°n."
    
    if len(gyms) == 1:
        gym = gyms[0]
        response = f"üèãÔ∏è **{gym['gymName']}**"
        if gym.get('distance_km'):
            response += f" - {format_distance_friendly(gym['distance_km'])}"
        if gym['address']:
            response += f"\nüìç {gym['address']}"
        if gym['hotResearch']:
            response += "\nüî• ƒê√¢y l√† ph√≤ng gym r·∫•t ƒë∆∞·ª£c y√™u th√≠ch!"
        return response
    
    elif len(gyms) <= 3:
        response = f"üèãÔ∏è **T√¨m th·∫•y {len(gyms)} ph√≤ng gym:**\n"
        for i, gym in enumerate(gyms, 1):
            name = gym['gymName']
            if gym['hotResearch']:
                name += " üî•"
            if gym.get('distance_km'):
                name += f" ({format_distance_friendly(gym['distance_km'])})"
            response += f"{i}. **{name}**\n"
        return response
    
    else:
        hot_gyms = [g for g in gyms if g['hotResearch']]
        response = f"üèãÔ∏è **T√¨m th·∫•y {len(gyms)} ph√≤ng gym!**\n"
        
        if hot_gyms:
            response += "üî• **C√°c ph√≤ng gym ph·ªï bi·∫øn:**\n"
            for i, gym in enumerate(hot_gyms, 1):
                name = gym['gymName']
                if gym.get('distance_km'):
                    name += f" ({format_distance_friendly(gym['distance_km'])})"
                response += f"{i}. **{name}**\n"
                
            # Hi·ªÉn th·ªã c√°c gym c√≤n l·∫°i
            other_gyms = [g for g in gyms if not g['hotResearch']]
            if other_gyms:
                response += "\n**C√°c ph√≤ng gym kh√°c:**\n"
                for i, gym in enumerate(other_gyms, len(hot_gyms) + 1):
                    name = gym['gymName']
                    if gym.get('distance_km'):
                        name += f" ({format_distance_friendly(gym['distance_km'])})"
                    response += f"{i}. **{name}**\n"
        else:
            response += "**T·∫•t c·∫£ ph√≤ng gym:**\n"
            for i, gym in enumerate(gyms, 1):
                name = gym['gymName']
                if gym.get('distance_km'):
                    name += f" ({format_distance_friendly(gym['distance_km'])})"
                response += f"{i}. **{name}**\n"
        
        return response

def classify_query_with_context(user_input, conversation_context):
    """Ph√¢n lo·∫°i truy v·∫•n v·ªõi ng·ªØ c·∫£nh h·ªôi tho·∫°i"""
    user_input_lower = user_input.lower()
    
    # Danh s√°ch t·ª´ kh√≥a ch·ªâ c√°c c√¢u h·ªèi KH√îNG c·∫ßn truy v·∫•n database
    non_gym_keywords = [
        # C√¢u h·ªèi c√° nh√¢n
        't√™n t√¥i', 't√™n c·ªßa t√¥i', 'l·∫∑p l·∫°i t√™n', 'nh·∫Øc l·∫°i t√™n', 
        'my name', 'what is my name', 'repeat my name',
        't√¥i t√™n', 't√¥i l√† ai', 'who am i',
        
        # Ch√†o h·ªèi v√† l·ªãch s·ª±
        'xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n', 'hey',
        'c·∫£m ∆°n', 'thank you', 'thanks', 'c√°m ∆°n',
        't·∫°m bi·ªát', 'bye', 'goodbye', 'ch√†o t·∫°m bi·ªát',
        
        # T∆∞ v·∫•n s·ª©c kh·ªèe chung (kh√¥ng c·∫ßn t√¨m gym c·ª• th·ªÉ)
        'l√†m sao ƒë·ªÉ', 'c√°ch ƒë·ªÉ', 'how to',
        'ƒÉn g√¨ ƒë·ªÉ', 'what to eat',
        'b√†i t·∫≠p n√†o', 'exercise for',
        'tƒÉng c√¢n', 'gi·∫£m c√¢n', 'lose weight', 'gain weight',
        
        # Ph·∫£n h·ªìi chung
        'ok', 'ƒë∆∞·ª£c r·ªìi', 't·ªët', 'good', 'fine', 'ƒë·ªìng √Ω'
    ]
    
    # Ki·ªÉm tra n·∫øu input ch·ª©a t·ª´ kh√≥a kh√¥ng c·∫ßn truy v·∫•n DB
    if any(keyword in user_input_lower for keyword in non_gym_keywords):
        return False, None
    
    # Danh s√°ch t·ª´ kh√≥a ch·ªâ r√µ c·∫ßn t√¨m ki·∫øm gym
    gym_search_keywords = [
        'gym', 'fitness', 'th·ªÉ d·ª•c', 'th·ªÉ h√¨nh', 't·∫≠p luy·ªán',
        'ph√≤ng gym', 'trung t√¢m', 'center', 'club',
        't√¨m', 'search', '·ªü ƒë√¢u', 'where', 'ƒë·ªãa ch·ªâ', 'address',
        'g·∫ßn', 'near', 'nearby', 'quanh', 'xung quanh',
        'qu·∫≠n', 'district', 'th√†nh ph·ªë', 'city'
    ]
    
    # Ch·ªâ ti·∫øp t·ª•c n·∫øu c√≥ t·ª´ kh√≥a li√™n quan ƒë·∫øn t√¨m ki·∫øm gym
    has_gym_intent = any(keyword in user_input_lower for keyword in gym_search_keywords)
    if not has_gym_intent:
        return False, None
    
    detected_intents = detect_search_intent(user_input)
    context_keywords = extract_search_keywords(conversation_context) if conversation_context else []
    
    # X·ª≠ l√Ω truy v·∫•n nh·∫≠n bi·∫øt ng·ªØ c·∫£nh
    if conversation_context:
        gym_names_in_context = re.findall(r'(\w+\s*(?:gym|fitness|center))', conversation_context.lower())
        
        if gym_names_in_context and any(word in user_input.lower() for word in ['kh√°c', 'other', 'n√†o kh√°c', 'c√≤n']):
            excluded_gyms = ' AND '.join([f"GymName NOT LIKE '%{name.split()[0]}%'" for name in gym_names_in_context])
            base_query = intelligent_gym_search(user_input)
            if base_query and excluded_gyms:
                enhanced_query = base_query.replace('WHERE Active = 1', f'WHERE Active = 1 AND {excluded_gyms}')
                return True, enhanced_query
    
    # S·ª≠ d·ª•ng ph√¢n lo·∫°i th√¥ng th∆∞·ªùng
    return classify_query(user_input)

# API Endpoints
@app.post("/chat", summary="Chat v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i", response_description="Tr·∫£ v·ªÅ ph·∫£n h·ªìi v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i")
async def chat_with_history(request: ChatRequest):
    return get_response_with_history(
        user_input=request.prompt,
        conversation_history=request.conversation_history,
        longitude=request.longitude,
        latitude=request.latitude
    )

# Ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
