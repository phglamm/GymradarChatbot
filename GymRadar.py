# Import c√°c th∆∞ vi·ªán c·ªët l√µi
import json
import os
import math
import re
from datetime import datetime
from difflib import SequenceMatcher
from typing import List, Optional

# Import c√°c th∆∞ vi·ªán b√™n ngo√†i
import google.generativeai as genai
import pyodbc
from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# C·∫•u h√¨nh Gemini API
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# C·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu
db_user = os.getenv('DB_USER')
db_password = os.getenv('DB_PASSWORD')

# X√¢y d·ª±ng chu·ªói k·∫øt n·ªëi
if not db_user and not db_password:
    conn_str = (
        r"DRIVER={ODBC Driver 17 for SQL Server};"
        f"SERVER={os.getenv('DB_SERVER')};"
        f"DATABASE={os.getenv('DB_NAME')};"
        "Trusted_Connection=yes;"
    )
else:
    conn_str = (
        r"DRIVER={ODBC Driver 17 for SQL Server};"
        f"SERVER={os.getenv('DB_SERVER')};"
        f"DATABASE={os.getenv('DB_NAME')};"
        f"UID={db_user};"
        f"PWD={db_password};"
    )

# K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu
try:
    print("ƒêang k·∫øt n·ªëi ƒë·∫øn c∆° s·ªü d·ªØ li·ªáu...")
    print(f"Server: {os.getenv('DB_SERVER')}")
    print(f"Database: {os.getenv('DB_NAME')}")
    
    conn = pyodbc.connect(conn_str)
    cursor = conn.cursor()
    print("K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu th√†nh c√¥ng!")
    
except pyodbc.Error as e:
    print(f"K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu th·∫•t b·∫°i: {e}")
    print("Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh c∆° s·ªü d·ªØ li·ªáu")
    conn = None
    cursor = None

# Kh·ªüi t·∫°o m√¥ h√¨nh Gemini
model = genai.GenerativeModel("gemini-2.0-flash")

class ChatRequest(BaseModel):
    prompt: str
    longitude: Optional[float] = None
    latitude: Optional[float] = None
    conversation_history: Optional[List[dict]] = []

class ChatResponse(BaseModel):
    promptResponse: str
    gyms: Optional[List[dict]] = None
    conversation_history: Optional[List[dict]] = []

def build_conversation_context(conversation_history: List[dict]) -> str:
    """X√¢y d·ª±ng ng·ªØ c·∫£nh t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    if not conversation_history:
        return ""
    
    context_parts = []
    for msg in conversation_history[-10:]:  # L·∫•y 10 tin nh·∫Øn g·∫ßn nh·∫•t l√†m ng·ªØ c·∫£nh
        role_label = "Ng∆∞·ªùi d√πng" if msg.get("role") == "user" else "GymRadar"
        content = sanitize_text_for_json(msg.get('content', ''))
        context_parts.append(f"{role_label}: {content}")
    
    return "\n".join(context_parts)

def sanitize_text_for_json(text: str) -> str:
    """L√†m s·∫°ch text ƒë·ªÉ tr√°nh l·ªói JSON parsing"""
    if not text:
        return ""
    
    # Thay th·∫ø c√°c k√Ω t·ª± ƒëi·ªÅu khi·ªÉn c√≥ th·ªÉ g√¢y l·ªói JSON
    try:
        # Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒëi·ªÅu khi·ªÉn kh√¥ng mong mu·ªën
        cleaned_text = text.replace('\x00', '').replace('\x08', '').replace('\x0c', '')
        cleaned_text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', cleaned_text)
        
        # ƒê·∫£m b·∫£o text c√≥ th·ªÉ ƒë∆∞·ª£c encode th√†nh JSON
        json.dumps(cleaned_text)
        return cleaned_text
    except (UnicodeDecodeError, json.JSONDecodeError):
        # N·∫øu v·∫´n c√≥ l·ªói, encode/decode ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá
        return text.encode('utf-8', errors='ignore').decode('utf-8', errors='ignore')

def safe_get_row_data(row):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ h√†ng c∆° s·ªü d·ªØ li·ªáu m·ªôt c√°ch an to√†n"""
    try:
        def get_attr(attr_name, default=None):
            try:
                return getattr(row, attr_name, default)
            except AttributeError:
                return default
        
        def get_bool_attr(attr_name, default=False):
            try:
                value = getattr(row, attr_name, default)
                if value is None:
                    return default
                if isinstance(value, int):
                    return bool(value)
                if isinstance(value, str):
                    return value.lower() in ('true', '1', 'yes', 'on')
                return bool(value)
            except AttributeError:
                return default
        
        def format_date(date_field):
            if date_field:
                try:
                    return date_field.isoformat() if hasattr(date_field, 'isoformat') else str(date_field)
                except:
                    return None
            return None
        
        gym_data = {
            "id": str(get_attr('Id', '')),
            "gymName": get_attr('GymName', ''),
            "since": format_date(get_attr('Since')),
            "address": get_attr('Address', ''),
            "representName": get_attr('RepresentName', ''),
            "taxCode": get_attr('TaxCode', ''),
            "longitude": get_attr('Longitude'),
            "latitude": get_attr('Latitude'),
            "qrCode": get_attr('QRCode', ''),
            "hotResearch": get_bool_attr('HotResearch', False),
            "accountId": str(get_attr('AccountId', '')) if get_attr('AccountId') else None,
            "active": get_bool_attr('Active', True),
            "createAt": format_date(get_attr('CreateAt')),
            "updateAt": format_date(get_attr('UpdateAt')),
            "deleteAt": format_date(get_attr('DeleteAt')),
            "mainImage": get_attr('MainImage', '')
        }
        
        # Handle distance for nearby queries
        distance = get_attr('distance_km')
        if distance is not None:
            try:
                gym_data["distance_km"] = round(float(distance), 2)
            except:
                gym_data["distance_km"] = 0
        
        return gym_data
        
    except Exception as e:
        print(f"L·ªói trong safe_get_row_data: {str(e)}")
        return {
            "id": "",
            "gymName": "Ph√≤ng gym kh√¥ng x√°c ƒë·ªãnh",
            "since": None,
            "address": "",
            "representName": "",
            "taxCode": "",
            "longitude": None,
            "latitude": None,
            "qrCode": "",
            "hotResearch": False,
            "accountId": None,
            "active": True,
            "createAt": None,
            "updateAt": None,
            "deleteAt": None,
            "mainImage": ""
        }

# Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI
app = FastAPI(
    title="GymRadar Chatbot AI",
    description="Chatbot t√¨m ki·∫øm ph√≤ng gym th√¥ng minh s·ª≠ d·ª•ng Gemini AI v√† SQL Server",
    version="2.0.0"
)

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# H√†m truy v·∫•n c∆° s·ªü d·ªØ li·ªáu
def query_database(query):
    if conn is None or cursor is None:
        print("K·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu kh√¥ng kh·∫£ d·ª•ng")
        return "L·ªói k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu"
    
    try:
        print(f"ƒêang th·ª±c thi truy v·∫•n: {query}")
        cursor.execute(query)
        results = cursor.fetchall()
        print(f"K·∫øt qu·∫£ truy v·∫•n: {len(results)} h√†ng")
        return results
    except pyodbc.Error as e:
        print(f"L·ªói c∆° s·ªü d·ªØ li·ªáu: {str(e)}")
        return f"L·ªói c∆° s·ªü d·ªØ li·ªáu: {str(e)}"

# X√¢y d·ª±ng truy v·∫•n SQL ƒë·ªÉ t√¨m gym g·∫ßn
def build_nearby_gym_query(longitude, latitude, max_distance_km=10):
    """X√¢y d·ª±ng truy v·∫•n SQL ƒë·ªÉ t√¨m gym g·∫ßn s·ª≠ d·ª•ng c√¥ng th·ª©c Haversine"""
    # T·ªëi ∆∞u h√≥a v·ªõi bounding box ƒë·ªÉ gi·∫£m t·∫£i t√≠nh to√°n
    lat_range = max_distance_km / 111.0  # 1 ƒë·ªô vƒ© ƒë·ªô ‚âà 111km
    lng_range = max_distance_km / (111.0 * abs(math.cos(math.radians(latitude))))
    
    return f"""
    WITH BoundedGyms AS (
        SELECT 
            Id, GymName, Since, Address, RepresentName, TaxCode,
            CAST(Longitude AS FLOAT) AS Longitude,
            CAST(Latitude AS FLOAT) AS Latitude,
            QRCode, HotResearch, AccountId, Active,
            CreateAt, UpdateAt, DeleteAt, MainImage
        FROM dbo.Gym 
        WHERE Active = 1
        AND CAST(Latitude AS FLOAT) BETWEEN {latitude - lat_range} AND {latitude + lat_range}
        AND CAST(Longitude AS FLOAT) BETWEEN {longitude - lng_range} AND {longitude + lng_range}
    ),
    DistanceCalculated AS (
        SELECT *,
            6371.0 * 2 * ASIN(
                SQRT(
                    POWER(SIN(RADIANS({latitude} - Latitude) / 2), 2) +
                    COS(RADIANS({latitude})) * COS(RADIANS(Latitude)) *
                    POWER(SIN(RADIANS({longitude} - Longitude) / 2), 2)
                )
            ) AS distance_km
        FROM BoundedGyms
    )
    SELECT * 
    FROM DistanceCalculated
    WHERE distance_km <= {max_distance_km}
    ORDER BY distance_km ASC, HotResearch DESC, GymName ASC;
    """

def get_nearby_distance_preference(user_input):
    """Ph√¢n t√≠ch ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ x√°c ƒë·ªãnh b√°n k√≠nh t√¨m ki·∫øm ph√π h·ª£p"""
    user_input_lower = user_input.lower()
    
    if any(word in user_input_lower for word in ["r·∫•t g·∫ßn", "very close", "walking distance", "ƒëi b·ªô"]):
        return 2  # 2km - kho·∫£ng c√°ch ƒëi b·ªô
    elif any(word in user_input_lower for word in ["g·∫ßn", "nearby", "close", "l√¢n c·∫≠n"]):
        return 5  # 5km - kho·∫£ng c√°ch v·ª´a ph·∫£i
    elif any(word in user_input_lower for word in ["xa m·ªôt ch√∫t", "farther", "trong khu v·ª±c", "khu v·ª±c"]):
        return 10  # 10km - khu v·ª±c r·ªông h∆°n
    elif any(word in user_input_lower for word in ["t·∫•t c·∫£", "all", "anywhere", "b·∫•t k·ª≥ ƒë√¢u"]):
        return 50  # 50km - r·∫•t r·ªông
    else:
        return 8  # M·∫∑c ƒë·ªãnh 8km

def format_distance_friendly(distance_km):
    """ƒê·ªãnh d·∫°ng kho·∫£ng c√°ch theo c√°ch th√¢n thi·ªán v·ªõi ng∆∞·ªùi d√πng"""
    if distance_km < 0.5:
        return f"{int(distance_km * 1000)}m"
    elif distance_km < 1:
        return f"{distance_km:.1f}km (ƒëi b·ªô ƒë∆∞·ª£c)" 
    elif distance_km < 3:
        return f"{distance_km:.1f}km (g·∫ßn)"
    elif distance_km < 5:
        return f"{distance_km:.1f}km (xe ƒë·∫°p/xe m√°y)"
    elif distance_km < 10:
        return f"{distance_km:.1f}km (√¥ t√¥/xe m√°y)"
    else:
        return f"{distance_km:.1f}km (xa)"

def normalize_vietnamese_text(text):
    """Chu·∫©n h√≥a vƒÉn b·∫£n ti·∫øng Vi·ªát ƒë·ªÉ t√¨m ki·∫øm t·ªët h∆°n"""
    if not text:
        return ""
    
    text = text.lower()
    
    # B·∫£n ƒë·ªì chuy·ªÉn ƒë·ªïi k√Ω t·ª± ti·∫øng Vi·ªát sang Latin
    char_map = {
        '√†': 'a', '√°': 'a', '·∫°': 'a', '·∫£': 'a', '√£': 'a',
        '√¢': 'a', '·∫ß': 'a', '·∫•': 'a', '·∫≠': 'a', '·∫©': 'a', '·∫´': 'a',
        'ƒÉ': 'a', '·∫±': 'a', '·∫Ø': 'a', '·∫∑': 'a', '·∫≥': 'a', '·∫µ': 'a',
        '√®': 'e', '√©': 'e', '·∫π': 'e', '·∫ª': 'e', '·∫Ω': 'e',
        '√™': 'e', '·ªÅ': 'e', '·∫ø': 'e', '·ªá': 'e', '·ªÉ': 'e', '·ªÖ': 'e',
        '√¨': 'i', '√≠': 'i', '·ªã': 'i', '·ªâ': 'i', 'ƒ©': 'i',
        '√≤': 'o', '√≥': 'o', '·ªç': 'o', '·ªè': 'o', '√µ': 'o',
        '√¥': 'o', '·ªì': 'o', '·ªë': 'o', '·ªô': 'o', '·ªï': 'o', '·ªó': 'o',
        '∆°': 'o', '·ªù': 'o', '·ªõ': 'o', '·ª£': 'o', '·ªü': 'o', '·ª°': 'o',
        '√π': 'u', '√∫': 'u', '·ª•': 'u', '·ªß': 'u', '≈©': 'u',
        '∆∞': 'u', '·ª´': 'u', '·ª©': 'u', '·ª±': 'u', '·ª≠': 'u', '·ªØ': 'u',
        '·ª≥': 'y', '√Ω': 'y', '·ªµ': 'y', '·ª∑': 'y', '·ªπ': 'y',
        'ƒë': 'd'
    }
    
    # Thay th·∫ø k√Ω t·ª± ti·∫øng Vi·ªát
    for viet_char, latin_char in char_map.items():
        text = text.replace(viet_char, latin_char)
    
    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, ch·ªâ gi·ªØ ch·ªØ c√°i v√† s·ªë
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    text = ' '.join(text.split())
    
    return text

def fuzzy_search_similarity(text1, text2):
    """T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa hai chu·ªói vƒÉn b·∫£n"""
    if not text1 or not text2:
        return 0
    
    normalized1 = normalize_vietnamese_text(text1)
    normalized2 = normalize_vietnamese_text(text2)
    
    return SequenceMatcher(None, normalized1, normalized2).ratio()

def extract_search_keywords(user_input):
    """Tr√≠ch xu·∫•t t·ª´ kh√≥a t√¨m ki·∫øm t·ª´ ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng"""
    stop_words = {
        't√¨m', 't√¨m ki·∫øm', 'find', 'search', 'c√≥', 'kh√¥ng', 'gym', 'ph√≤ng gym', 
        'n√†o', 'ƒë√¢u', 'where', 'what', 'g√¨', 'l√†', '·ªü', 't·∫°i', 'trong', 'c·ªßa',
        'm·ªôt', 'v√†i', 'nh·ªØng', 'c√°c', 'the', 'a', 'an', 'and', 'or', 'for'
    }
    
    normalized = normalize_vietnamese_text(user_input)
    words = normalized.split()
    keywords = [word for word in words if word not in stop_words and len(word) >= 2]
    
    return keywords

def intelligent_gym_search(user_input):
    """T√¨m ki·∫øm gym th√¥ng minh v·ªõi kh·∫£ nƒÉng kh·ªõp m·ªù"""
    try:
        # Ki·ªÉm tra ƒë·∫ßu v√†o
        if not user_input or not isinstance(user_input, str):
            return None
        
        user_input_lower = user_input.lower()
        
        # Danh s√°ch t·ª´ kh√≥a ch·ªâ r√µ KH√îNG c·∫ßn t√¨m ki·∫øm gym
        non_gym_indicators = [
            'xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n',
            'c·∫£m ∆°n', 'thank you', 'thanks',
            't√™n t√¥i', 'my name', 'l·∫∑p l·∫°i t√™n',
            'l√†m sao ƒë·ªÉ', 'how to', 'c√°ch ƒë·ªÉ',
            'ƒÉn g√¨', 'what to eat', 'th·ªùi ti·∫øt',
            'ok', 'ƒë∆∞·ª£c r·ªìi', 'good', 't·∫°m bi·ªát'
        ]
        
        # N·∫øu c√≥ t·ª´ kh√≥a kh√¥ng li√™n quan gym, return None
        if any(indicator in user_input_lower for indicator in non_gym_indicators):
            return None
        
        # Danh s√°ch t·ª´ kh√≥a b·∫Øt bu·ªôc ƒë·ªÉ t√¨m ki·∫øm gym
        gym_required_keywords = [
            'gym', 'fitness', 'th·ªÉ d·ª•c', 'th·ªÉ h√¨nh',
            'ph√≤ng gym', 'trung t√¢m', 'center', 'club',
            't√¨m', 'search', '·ªü ƒë√¢u', 'where', 'ƒë·ªãa ch·ªâ',
            'g·∫ßn', 'near', 'nearby', 'quanh',
            'qu·∫≠n', 'district', 'th√†nh ph·ªë'
        ]
        
        # Ch·ªâ ti·∫øp t·ª•c n·∫øu c√≥ t·ª´ kh√≥a li√™n quan gym
        has_gym_keyword = any(keyword in user_input_lower for keyword in gym_required_keywords)
        if not has_gym_keyword:
            return None
            
        intents = detect_search_intent(user_input)
        keywords = extract_search_keywords(user_input)
        
        base_conditions = ["Active = 1"]
        
        # L·ªçc gym hot n·∫øu t√¨m ki·∫øm ph·ªï bi·∫øn
        if 'popular_search' in intents:
            base_conditions.append("HotResearch = 1")
        
        # X√¢y d·ª±ng ƒëi·ªÅu ki·ªán t√¨m ki·∫øm t·ª´ keywords
        search_conditions = []
        if keywords:
            for keyword in keywords:
                # Ki·ªÉm tra keyword c√≥ h·ª£p l·ªá kh√¥ng
                if keyword and isinstance(keyword, str) and keyword.lower() not in ['hot', 'n·ªïi', 'ti·∫øng', 'ph·ªï', 'bi·∫øn', 'y√™u', 'th√≠ch', 't·ªët', 'nh·∫•t', 'best']:
                    # Escape single quotes ƒë·ªÉ tr√°nh SQL injection
                    safe_keyword = keyword.replace("'", "''")
                    search_conditions.extend([
                        f"GymName LIKE '%{safe_keyword}%'",
                        f"Address LIKE '%{safe_keyword}%'",
                        f"RepresentName LIKE '%{safe_keyword}%'"
                    ])
        
        # X√¢y d·ª±ng m·ªánh ƒë·ªÅ WHERE
        where_clause = " AND ".join(base_conditions)
        if search_conditions:
            keyword_clause = " OR ".join(search_conditions)
            where_clause += f" AND ({keyword_clause})"
        elif 'popular_search' not in intents:
            return None
        
        # X√¢y d·ª±ng truy v·∫•n SQL
        first_keyword = None
        if keywords:
            for k in keywords:
                if k and isinstance(k, str) and k.lower() not in ['hot', 'n·ªïi', 'ti·∫øng', 'ph·ªï', 'bi·∫øn', 'y√™u', 'th√≠ch', 't·ªët', 'nh·∫•t', 'best']:
                    first_keyword = k.replace("'", "''")  # Escape single quotes
                    break
        
        if first_keyword:
            sql_query = f"""
            SELECT *, 
                   CASE WHEN HotResearch = 1 THEN 10 ELSE 0 END as hot_score,
                   CASE 
                       WHEN GymName LIKE '%{first_keyword}%' THEN 20
                       WHEN Address LIKE '%{first_keyword}%' THEN 15
                       WHEN RepresentName LIKE '%{first_keyword}%' THEN 10
                       ELSE 5
                   END as relevance_score
            FROM dbo.Gym 
            WHERE {where_clause}
            ORDER BY hot_score DESC, relevance_score DESC, GymName ASC
            """
        else:
            sql_query = f"""
            SELECT *, 
                   CASE WHEN HotResearch = 1 THEN 10 ELSE 0 END as hot_score,
                   5 as relevance_score
            FROM dbo.Gym 
            WHERE {where_clause}
            ORDER BY hot_score DESC, GymName ASC
            """
        
        return sql_query
        
    except Exception as e:
        print(f"L·ªói trong intelligent_gym_search: {str(e)}")
        return None

def detect_search_intent(user_input):
    """Ph√°t hi·ªán √Ω ƒë·ªãnh t√¨m ki·∫øm t·ª´ ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng"""
    user_lower = user_input.lower()
    
    intent_patterns = {
        'location_search': [r'(g·∫ßn|near|nearby|xung quanh|l√¢n c·∫≠n|quanh ƒë√¢y)', r'(district \d+|qu·∫≠n \d+|huy·ªán)'],
        'name_search': [r'(t√¨m .+ gym|gym .+|.+ fitness|.+ center)'],
        'popular_search': [r'(hot|n·ªïi ti·∫øng|ph·ªï bi·∫øn|ƒë∆∞·ª£c y√™u th√≠ch|t·ªët nh·∫•t|best)', r'(gym hot|ph√≤ng gym hot|fitness hot)'],
        'new_search': [r'(m·ªõi|new|v·ª´a m·ªü|recently|g·∫ßn ƒë√¢y)'],
        'old_search': [r'(c≈©|old|l√¢u nƒÉm|uy t√≠n|established)'],
        'price_search': [r'(r·∫ª|cheap|affordable|gi√° t·ªët|budget)'],
        'equipment_search': [r'(thi·∫øt b·ªã|equipment|m√°y t·∫≠p|facilities)']
    }
    
    detected_intents = []
    for intent, patterns in intent_patterns.items():
        for pattern in patterns:
            if re.search(pattern, user_lower):
                detected_intents.append(intent)
                break
    
    return detected_intents

def classify_query(user_input):
    """Ph√¢n lo·∫°i truy v·∫•n v√† t·∫°o SQL n·∫øu c·∫ßn"""
    prompt = f"""
    B·∫°n l√† chuy√™n gia ph√¢n t√≠ch truy v·∫•n t√¨m ki·∫øm gym. Nhi·ªám v·ª•: Ph√¢n t√≠ch truy v·∫•n v√† quy·∫øt ƒë·ªãnh c√≥ c·∫ßn truy v·∫•n database hay kh√¥ng.

    CH·ªà T·∫†O SQL KHI:
    - T√¨m ki·∫øm gym theo t√™n: "gym Elite", "t√¨m California"
    - T√¨m ki·∫øm theo ƒë·ªãa ƒëi·ªÉm: "gym ·ªü qu·∫≠n 1", "ph√≤ng gym B√¨nh Th·∫°nh"
    - T√¨m gym ph·ªï bi·∫øn: "gym hot", "gym n·ªïi ti·∫øng", "top gym"
    - Li·ªát k√™ gym: "t·∫•t c·∫£ gym", "danh s√°ch gym", "c√≥ nh·ªØng gym n√†o"
    - T√¨m theo ti√™u ch√≠: "gym m·ªõi", "gym c√≥ b·ªÉ b∆°i"

    LU√îN TR·∫¢ V·ªÄ "NO_DB_QUERY" KHI:
    - Ch√†o h·ªèi: "xin ch√†o", "hello", "hi"
    - C√¢u h·ªèi c√° nh√¢n: "t√™n t√¥i l√† g√¨", "l·∫∑p l·∫°i t√™n t√¥i"
    - T∆∞ v·∫•n chung: "l√†m sao ƒë·ªÉ tƒÉng c√¢n", "b√†i t·∫≠p n√†o t·ªët"
    - C√¢u h·ªèi v·ªÅ s·ª©c kh·ªèe: "ƒÉn g√¨ ƒë·ªÉ tƒÉng c∆°"
    - H·ªôi tho·∫°i t·ª± nhi√™n: "c·∫£m ∆°n", "ok", "ƒë∆∞·ª£c r·ªìi"
    - C√¢u h·ªèi kh√¥ng li√™n quan gym: "th·ªùi ti·∫øt h√¥m nay", "gi√° c·∫£ th·∫ø n√†o"

    C∆° s·ªü d·ªØ li·ªáu: dbo.Gym
    C·ªôt: Id, GymName, Address, HotResearch (1=ph·ªï bi·∫øn), Active, CreateAt, etc.
    
    Lu√¥n bao g·ªìm: WHERE Active = 1
    
    V√≠ d·ª• SQL:
    - "gym Elite" ‚Üí SELECT * FROM dbo.Gym WHERE Active = 1 AND GymName LIKE '%Elite%'
    - "gym ·ªü qu·∫≠n 1" ‚Üí SELECT * FROM dbo.Gym WHERE Active = 1 AND Address LIKE '%District 1%'
    - "gym hot" ‚Üí SELECT * FROM dbo.Gym WHERE Active = 1 AND HotResearch = 1

    Truy v·∫•n: "{user_input}"
    
    Tr·∫£ v·ªÅ ch·ªâ SQL ho·∫∑c "NO_DB_QUERY":
    """

    try:
        # Th·ª≠ t√¨m ki·∫øm th√¥ng minh tr∆∞·ªõc
        intelligent_query = intelligent_gym_search(user_input)
        if intelligent_query:
            return True, intelligent_query
        
        # S·ª≠ d·ª•ng AI ph√¢n t√≠ch
        response = model.generate_content(prompt)
        result = response.text.strip().replace("```sql", "").replace("```", "")
        
        if result == "NO_DB_QUERY" or "NO_DB_QUERY" in result:
            return False, None
        if result.lower().startswith("select") and "from dbo.gym" in result.lower():
            return True, result

        return False, None
    except Exception as e:
        print(f"L·ªói trong classify_query: {str(e)}")
        return False, None

def get_response_with_history(user_input, conversation_history=None, longitude=None, latitude=None):
    """H√†m ch√≠nh ƒë·ªÉ x·ª≠ l√Ω y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i"""
    try:
        if conversation_history is None:
            conversation_history = []
        
        conversation_context = build_conversation_context(conversation_history)
        
        # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠
        current_conversation = conversation_history.copy()
        current_conversation.append({
            "role": "user",
            "content": sanitize_text_for_json(user_input),
            "timestamp": datetime.now().isoformat()
        })
        
        # X·ª≠ l√Ω t√¨m ki·∫øm g·∫ßn v·ªõi t·ªça ƒë·ªô
        if longitude and latitude and any(keyword in user_input.lower() for keyword in ["g·∫ßn", "near", "nearby", "xung quanh", "l√¢n c·∫≠n", "g·∫ßn ƒë√¢y", "quanh ƒë√¢y"]):
            max_distance = get_nearby_distance_preference(user_input)
            sql_query = build_nearby_gym_query(longitude, latitude, max_distance)
            results = query_database(sql_query)

            if isinstance(results, str) or not results:
                response_text = f"ü§î Kh√¥ng t√¨m th·∫•y gym n√†o trong b√°n k√≠nh {max_distance}km. H√£y th·ª≠ m·ªü r·ªông khu v·ª±c t√¨m ki·∫øm!"
                current_conversation.append({
                    "role": "assistant",
                    "content": sanitize_text_for_json(response_text),
                    "timestamp": datetime.now().isoformat()
                })
                return {
                    "promptResponse": sanitize_text_for_json(response_text),
                    "conversation_history": current_conversation
                }

            gyms = [safe_get_row_data(row) for row in results]
            prompt_response = create_simple_response(gyms, user_input, is_nearby=True)

            current_conversation.append({
                "role": "assistant",
                "content": sanitize_text_for_json(prompt_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "gyms": gyms, 
                "promptResponse": sanitize_text_for_json(prompt_response),
                "conversation_history": current_conversation
            }
        
        # Truy v·∫•n c∆° s·ªü d·ªØ li·ªáu th√¥ng th∆∞·ªùng
        is_db_query, sql_query = classify_query_with_context(user_input, conversation_context)
        if is_db_query:
            results = query_database(sql_query)
            if isinstance(results, str) or not results:
                response_text = "ü§î Kh√¥ng t√¨m th·∫•y gym n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ c·ªßa b·∫°n. H√£y th·ª≠ t√¨m ki·∫øm kh√°c!"
                current_conversation.append({
                    "role": "assistant",
                    "content": sanitize_text_for_json(response_text),
                    "timestamp": datetime.now().isoformat()
                })
                return {
                    "promptResponse": sanitize_text_for_json(response_text),
                    "conversation_history": current_conversation
                }

            gyms = [safe_get_row_data(row) for row in results]
            prompt_response = create_simple_response(gyms, user_input)

            current_conversation.append({
                "role": "assistant",
                "content": sanitize_text_for_json(prompt_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "gyms": gyms, 
                "promptResponse": sanitize_text_for_json(prompt_response),
                "conversation_history": current_conversation
            }

        # H·ªôi tho·∫°i t·ª± do v·ªõi Gemini
        enhanced_context = f"""
        B·∫°n l√† GymRadar AI - tr·ª£ l√Ω t√¨m ki·∫øm ph√≤ng gym th√¢n thi·ªán v√† chuy√™n nghi·ªáp t·∫°i Vi·ªát Nam.
        
        Kh·∫£ nƒÉng:
        - ƒê∆∞a ra g·ª£i √Ω ph√≤ng gym v√† th√¥ng tin chi ti·∫øt
        - T∆∞ v·∫•n th·ªÉ d·ª•c v√† l·ªãch t·∫≠p luy·ªán d·ª±a tr√™n m·ª•c ti√™u
        - Chia s·∫ª ki·∫øn th·ª©c v·ªÅ s·ª©c kh·ªèe v√† th·ªÉ h√¨nh
        - Nh·ªõ ng·ªØ c·∫£nh h·ªôi tho·∫°i ƒë·ªÉ t∆∞ v·∫•n nh·∫•t qu√°n
        
        Phong c√°ch: Th√¢n thi·ªán, chuy√™n nghi·ªáp, hi·ªÉu bi·∫øt. S·ª≠ d·ª•ng emoji ph√π h·ª£p.
        Lu√¥n k·∫øt th√∫c b·∫±ng c√¢u h·ªèi ho·∫∑c g·ª£i √Ω h√†nh ƒë·ªông.
        
        L·ªãch s·ª≠ h·ªôi tho·∫°i:
        {conversation_context}
        """
        
        prompt = f"{enhanced_context}\n\nC√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_input}"
        response = model.generate_content(prompt)
        
        current_conversation.append({
            "role": "assistant", 
            "content": sanitize_text_for_json(response.text),
            "timestamp": datetime.now().isoformat()
        })
        
        return {
            "promptResponse": sanitize_text_for_json(response.text),
            "conversation_history": current_conversation
        }

    except Exception as e:
        print(f"L·ªói trong get_response_with_history: {str(e)}")
        error_response = "ü§ñ Xin l·ªói, ƒë√£ x·∫£y ra l·ªói h·ªá th·ªëng. Vui l√≤ng th·ª≠ l·∫°i!"
        
        if 'current_conversation' in locals():
            current_conversation.append({
                "role": "assistant", 
                "content": sanitize_text_for_json(error_response),
                "timestamp": datetime.now().isoformat()
            })
            return {
                "promptResponse": sanitize_text_for_json(error_response),
                "conversation_history": current_conversation
            }
        
        return {"promptResponse": sanitize_text_for_json(error_response)}

def create_simple_response(gyms, user_input, is_nearby=False):
    """T·∫°o ph·∫£n h·ªìi ƒë∆°n gi·∫£n cho k·∫øt qu·∫£ t√¨m ki·∫øm gym"""
    if not gyms:
        return "ü§î Kh√¥ng t√¨m th·∫•y gym n√†o ph√π h·ª£p v·ªõi ti√™u ch√≠ c·ªßa b·∫°n."
    
    if len(gyms) == 1:
        gym = gyms[0]
        response = f"üèãÔ∏è **{gym['gymName']}**"
        if gym.get('distance_km'):
            response += f" - {format_distance_friendly(gym['distance_km'])}"
        if gym['address']:
            response += f"\nüìç {gym['address']}"
        if gym['hotResearch']:
            response += "\nüî• ƒê√¢y l√† ph√≤ng gym r·∫•t ƒë∆∞·ª£c y√™u th√≠ch!"
        return response
    
    elif len(gyms) <= 3:
        response = f"üèãÔ∏è **T√¨m th·∫•y {len(gyms)} ph√≤ng gym:**\n"
        for i, gym in enumerate(gyms, 1):
            name = gym['gymName']
            if gym['hotResearch']:
                name += " üî•"
            if gym.get('distance_km'):
                name += f" ({format_distance_friendly(gym['distance_km'])})"
            response += f"{i}. **{name}**\n"
        return response
    
    else:
        hot_gyms = [g for g in gyms if g['hotResearch']]
        response = f"üèãÔ∏è **T√¨m th·∫•y {len(gyms)} ph√≤ng gym!**\n"
        
        if hot_gyms:
            response += "üî• **G·ª£i √Ω ph·ªï bi·∫øn:**\n"
            for gym in hot_gyms[:3]:
                name = gym['gymName']
                if gym.get('distance_km'):
                    name += f" ({format_distance_friendly(gym['distance_km'])})"
                response += f"‚Ä¢ **{name}**\n"
        else:
            response += "**Top 3 g·ª£i √Ω:**\n"
            for gym in gyms[:3]:
                name = gym['gymName']
                if gym.get('distance_km'):
                    name += f" ({format_distance_friendly(gym['distance_km'])})"
                response += f"‚Ä¢ **{name}**\n"
        
        if len(gyms) > 3:
            response += f"\n...v√† {len(gyms) - 3} ph√≤ng gym kh√°c n·ªØa!"
        
        return response

def classify_query_with_context(user_input, conversation_context):
    """Ph√¢n lo·∫°i truy v·∫•n v·ªõi ng·ªØ c·∫£nh h·ªôi tho·∫°i"""
    user_input_lower = user_input.lower()
    
    # Danh s√°ch t·ª´ kh√≥a ch·ªâ c√°c c√¢u h·ªèi KH√îNG c·∫ßn truy v·∫•n database
    non_gym_keywords = [
        # C√¢u h·ªèi c√° nh√¢n
        't√™n t√¥i', 't√™n c·ªßa t√¥i', 'l·∫∑p l·∫°i t√™n', 'nh·∫Øc l·∫°i t√™n', 
        'my name', 'what is my name', 'repeat my name',
        't√¥i t√™n', 't√¥i l√† ai', 'who am i',
        
        # Ch√†o h·ªèi v√† l·ªãch s·ª±
        'xin ch√†o', 'hello', 'hi', 'ch√†o b·∫°n', 'hey',
        'c·∫£m ∆°n', 'thank you', 'thanks', 'c√°m ∆°n',
        't·∫°m bi·ªát', 'bye', 'goodbye', 'ch√†o t·∫°m bi·ªát',
        
        # T∆∞ v·∫•n s·ª©c kh·ªèe chung (kh√¥ng c·∫ßn t√¨m gym c·ª• th·ªÉ)
        'l√†m sao ƒë·ªÉ', 'c√°ch ƒë·ªÉ', 'how to',
        'ƒÉn g√¨ ƒë·ªÉ', 'what to eat',
        'b√†i t·∫≠p n√†o', 'exercise for',
        'tƒÉng c√¢n', 'gi·∫£m c√¢n', 'lose weight', 'gain weight',
        
        # Ph·∫£n h·ªìi chung
        'ok', 'ƒë∆∞·ª£c r·ªìi', 't·ªët', 'good', 'fine', 'ƒë·ªìng √Ω'
    ]
    
    # Ki·ªÉm tra n·∫øu input ch·ª©a t·ª´ kh√≥a kh√¥ng c·∫ßn truy v·∫•n DB
    if any(keyword in user_input_lower for keyword in non_gym_keywords):
        return False, None
    
    # Danh s√°ch t·ª´ kh√≥a ch·ªâ r√µ c·∫ßn t√¨m ki·∫øm gym
    gym_search_keywords = [
        'gym', 'fitness', 'th·ªÉ d·ª•c', 'th·ªÉ h√¨nh', 't·∫≠p luy·ªán',
        'ph√≤ng gym', 'trung t√¢m', 'center', 'club',
        't√¨m', 'search', '·ªü ƒë√¢u', 'where', 'ƒë·ªãa ch·ªâ', 'address',
        'g·∫ßn', 'near', 'nearby', 'quanh', 'xung quanh',
        'qu·∫≠n', 'district', 'th√†nh ph·ªë', 'city'
    ]
    
    # Ch·ªâ ti·∫øp t·ª•c n·∫øu c√≥ t·ª´ kh√≥a li√™n quan ƒë·∫øn t√¨m ki·∫øm gym
    has_gym_intent = any(keyword in user_input_lower for keyword in gym_search_keywords)
    if not has_gym_intent:
        return False, None
    
    detected_intents = detect_search_intent(user_input)
    context_keywords = extract_search_keywords(conversation_context) if conversation_context else []
    
    # X·ª≠ l√Ω truy v·∫•n nh·∫≠n bi·∫øt ng·ªØ c·∫£nh
    if conversation_context:
        gym_names_in_context = re.findall(r'(\w+\s*(?:gym|fitness|center))', conversation_context.lower())
        
        if gym_names_in_context and any(word in user_input.lower() for word in ['kh√°c', 'other', 'n√†o kh√°c', 'c√≤n']):
            excluded_gyms = ' AND '.join([f"GymName NOT LIKE '%{name.split()[0]}%'" for name in gym_names_in_context])
            base_query = intelligent_gym_search(user_input)
            if base_query and excluded_gyms:
                enhanced_query = base_query.replace('WHERE Active = 1', f'WHERE Active = 1 AND {excluded_gyms}')
                return True, enhanced_query
    
    # S·ª≠ d·ª•ng ph√¢n lo·∫°i th√¥ng th∆∞·ªùng
    return classify_query(user_input)

# API Endpoints
@app.post("/chat", summary="Chat v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i", response_description="Tr·∫£ v·ªÅ ph·∫£n h·ªìi v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i")
async def chat_with_history(request: ChatRequest):
    return get_response_with_history(
        user_input=request.prompt,
        conversation_history=request.conversation_history,
        longitude=request.longitude,
        latitude=request.latitude
    )

# Ch·∫°y ·ª©ng d·ª•ng
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8002)
